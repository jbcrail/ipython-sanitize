#!/usr/bin/env python

import click
import nbconvert
import requests


def start():
    import sys
    import traceback

    try:
        cli(obj={})
    except KeyboardInterrupt:
        click.echo("Interrupted by Ctrl-C.")
        sys.exit(1)
    except Exception:
        click.echo(traceback.format_exc(), err=True)
        sys.exit(1)


CONTEXT_SETTINGS = dict(help_option_names=['-h', '--help'])


@click.group(context_settings=CONTEXT_SETTINGS)
@click.version_option(prog_name="ipython-sanitize", version="0.0.1")
@click.pass_context
def cli(ctx):
    """
    Extract and validate items in IPython notebooks.
    """
    ctx.obj = {}


def export_as_html(filename):
    html_exporter = nbconvert.HTMLExporter()
    html_exporter.template_file = 'basic'
    body, _ = html_exporter.from_filename(filename)
    return body


def export_as_python(filename):
    py_exporter = nbconvert.PythonExporter()
    output, _ = py_exporter.from_filename(filename)
    return output.encode('utf8')


def module_exists(name):
    try:
        __import__(name)
    except ImportError:
        return False
    else:
        return True


def url_exists(url):
    response = requests.head(url)
    if not response.ok:
        response = requests.get(url)
    return response.ok


@cli.command(short_help="Extract/validate Python modules")
@click.pass_context
@click.option("--stdlib/--no-stdlib",
              default=False,
              help="Toggle whether to include Python standard library")
@click.option("--verify/--no-verify",
              default=True,
              help="Toggle whether to verify modules")
@click.argument('notebooks', nargs=-1)
def modules(ctx, notebooks, stdlib, verify):
    import ast
    import re
    from stdlib_list import stdlib_list

    class ModuleReader(ast.NodeVisitor):
        def __init__(self):
            self.imports = set()

        def generic_visit(self, node):
            ast.NodeVisitor.generic_visit(self, node)
            return list(self.imports)

        def visit_Import(self, node):
            for alias in node.names:
                self.imports.add(alias.name)

        def visit_ImportFrom(self, node):
            self.imports.add(node.module)

    def get_ipython_modules(s):
        root = ast.parse(s)
        return ModuleReader().visit(root)

    default_modules = stdlib_list()
    modules = set()

    for f in notebooks:
        for module in get_ipython_modules(export_as_python(f)):
            if not stdlib and module in default_modules:
                continue
            if '.' in module:
                modules.add(re.sub(r'\..*', '', module))
            else:
                modules.add(module)

    def output_color(module, verify):
        if not verify:
            return None
        return "green" if module_exists(module) else "red"

    for module in sorted(modules):
        click.secho(module, fg=output_color(module, verify))


@cli.command(short_help="Extract/validate Markdown URLs")
@click.pass_context
@click.option("--verify/--no-verify",
              default=True,
              help="Toggle whether to verify URLs")
@click.argument('notebooks', nargs=-1)
def urls(ctx, notebooks, verify):
    from bs4 import BeautifulSoup
    import re

    REGEX_URL = re.compile('^(http|https):.+')

    def output_color(url, verify):
        if not verify:
            return None
        return "green" if url_exists(url) else "red"

    for f in notebooks:
        html = export_as_html(f)
        soup = BeautifulSoup(html, 'html.parser')
        for link in soup.find_all('a'):
            url = link.get('href')
            if REGEX_URL.match(url):
                click.secho("{}: {}".format(f, url), fg=output_color(url, verify))


@cli.command(short_help="Extract/validate Markdown images")
@click.pass_context
@click.option("--verify/--no-verify",
              default=True,
              help="Toggle whether to verify images")
@click.argument('notebooks', nargs=-1)
def images(ctx, notebooks, verify):
    from bs4 import BeautifulSoup
    import re

    REGEX_URL = re.compile('^(http|https):.+')

    def output_color(image, verify):
        if not verify:
            return None
        return "green" if url_exists(image) else "red"

    for f in notebooks:
        html = export_as_html(f)
        soup = BeautifulSoup(html, 'html.parser')
        for link in soup.find_all('img'):
            url = link.get('src')
            if REGEX_URL.match(url):
                click.secho("{}: {}".format(f, url), fg=output_color(url, verify))


if __name__ == '__main__':
    start()
